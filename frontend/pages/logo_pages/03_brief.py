# pages/logo_pages/brief.py
# TITLE: ğŸ“‹ Step 3/4. Brief â€” ìš”êµ¬ì‚¬í•­ ì…ë ¥ (ìŠ¤ì¼€ì¹˜/ë§ˆìŠ¤í¬ ê°ì§€ â†’ SDXL í”„ë¡¬í”„íŠ¸ ìë™ ë¶„ê¸° + íŒ”ë ˆíŠ¸ ìƒ‰ìƒ ì œí•œ + ì»¨íŠ¸ë¡¤ íŒíŠ¸)

from __future__ import annotations

TITLE = "ğŸ“‹ Step 3/4. Brief â€” ìš”êµ¬ì‚¬í•­ ì…ë ¥"

import os, io, json, base64, uuid, colorsys, time, re
from typing import List, Optional, Tuple, Dict, Any
from pydantic import BaseModel, Field
from PIL import Image, ImageOps
import streamlit as st
import requests

# =============================
# í™˜ê²½ ë³€ìˆ˜
# =============================
BACKEND_BASE      = os.environ.get("LOGO_BACKEND_URL", "http://127.0.0.1:8000")
BRIEF_ENDPOINT    = os.environ.get("LOGO_BRIEF_ENDPOINT", "/logo/briefs")
GENERATE_ENDPOINT = os.environ.get("LOGO_GENERATE_ENDPOINT", "/logo/generate")
JOB_ENDPOINT      = os.environ.get("LOGO_JOB_ENDPOINT", "/logo/generate/{job_id}")
BRIEF_POST_URL    = f"{BACKEND_BASE.rstrip('/')}{BRIEF_ENDPOINT}"
GENERATE_URL      = f"{BACKEND_BASE.rstrip('/')}{GENERATE_ENDPOINT}"
NEXT_PAGE_PATH    = os.environ.get("LOGO_NEXT_PAGE", "pages/logo_pages/04_generate.py")

# =============================
# ìœ í‹¸
# =============================
def _k(name: str) -> str:
    return f"brief::{name}"

def file_to_pil(uploaded) -> Image.Image:
    img = Image.open(uploaded).convert("RGB")
    return ImageOps.exif_transpose(img)

def pil_to_b64_png(img: Image.Image) -> str:
    buf = io.BytesIO()
    img.save(buf, format="PNG")
    return base64.b64encode(buf.getvalue()).decode("utf-8")

@st.cache_data(show_spinner=False)
def extract_palette(img: Image.Image, n: int = 5) -> List[str]:
    im = img.copy()
    im.thumbnail((200, 200))
    colors = im.getcolors(maxcolors=2_000_000) or []
    if not colors:
        return ["#000000", "#FFFFFF"]
    colors.sort(key=lambda x: x[0], reverse=True)
    hexes, seen = [], set()
    for _, rgb in colors:
        r, g, b = rgb[:3]
        h, s, v = colorsys.rgb_to_hsv(r/255.0, g/255.0, b/255.0)
        if (v > 0.97 and s < 0.10) or (v < 0.08) or (s < 0.08):
            continue
        hcode = f"#{r:02X}{g:02X}{b:02X}"
        if hcode not in seen:
            hexes.append(hcode); seen.add(hcode)
        if len(hexes) >= n: break
    if not hexes:
        hexes = ["#3B3B3B", "#BEA38A", "#6B4F36", "#C8B09A", "#8F6D52"][:n]
    return hexes

def render_palette_swatches(hexes: List[str]):
    cols = st.columns(len(hexes))
    for c, h in zip(cols, hexes):
        with c:
            st.markdown(
                f"""
                <div style="border-radius:10px;border:1px solid #ddd;height:40px;background:{h};"></div>
                <div style="text-align:center;font-size:12px;margin-top:6px;">{h}</div>
                """,
                unsafe_allow_html=True,
            )

def _nav_to_next_step():
    try:
        st.switch_page(NEXT_PAGE_PATH); return
    except Exception:
        pass
    try:
        st.query_params.update({"step":"4"})
    except Exception:
        st.experimental_set_query_params(step="4")
    finally:
        st.session_state["logo_step"] = 4
        st.rerun()

# =============================
# ë°ì´í„° ëª¨ë¸
# =============================
class PromptBrief(BaseModel):
    cafe_name: str = Field(description="ì¹´í˜ëª…(ë¸Œëœë“œëª…)")
    copy_text: str = Field(description="ìƒì„±í•˜ê³  ì‹¶ì€ í…ìŠ¤íŠ¸")
    layout: str    = Field(description="ë°°ê²½/êµ¬ë„")
    avoid: str     = Field(description="í”¼í•´ì•¼ í•  ê²ƒ")
    strengths: str = Field(description="í•µì‹¬ ì¥ì ")
    style: str     = Field(description="ì›í•˜ëŠ” ìŠ¤íƒ€ì¼")
    notes: str     = Field(description="ì°¸ê³  ì‚¬í•­")
    model_hint: str = Field(description="ì‚¬ìš©í•  ëª¨ë¸ íŒíŠ¸ (ì˜ˆ: SDXL Base)")

# =============================
# í”„ë¡¬í”„íŠ¸ ë¹Œë”(ë°±ì—”ë“œ LLMì´ ì°¸ê³ í•  ìˆ˜ ìˆë„ë¡ ê¸°ë³¸ ë²ˆë“¤ ìƒì„±)
# =============================
def _infer_logo_type(copy_text: str, layout: str, style: str) -> str:
    text = f"{copy_text} {layout} {style}".lower()
    if any(k in text for k in ["ì— ë¸”ëŸ¼", "emblem", "badge", "round", "seal", "ì›í˜•"]):
        if any(k in text for k in ["í…ìŠ¤íŠ¸", "wordmark", "íƒ€ì´í¬", "type"]):
            return "combination mark (emblem + wordmark)"
        return "emblem"
    if any(k in text for k in ["wordmark", "íƒ€ì´í¬", "type", "ì„œì²´", "lettering"]):
        return "wordmark"
    return "combination mark"

def _normalize_phrase(s: str) -> str:
    s = re.sub(r"\s+", " ", s or "").strip()
    return s

def _build_positive_prompt(brief: PromptBrief, palette: Optional[List[str]], logo_type: str,
                           sketch_present: bool, mask_present: bool) -> str:
    core = [
        f"{logo_type} logo for cafe '{brief.cafe_name}'",
        f"logo text: {brief.copy_text}",
        "clean vector aesthetic, sharp edges, smooth bezier curves",
        "minimal, professional brand identity, balanced spacing, consistent stroke weight",
        "high contrast, print-ready, flat colors, no gradients unless essential",
    ]
    if brief.layout: core.append(_normalize_phrase(brief.layout))
    if brief.style:  core.append(_normalize_phrase(brief.style))
    if brief.strengths: core.append(f"brand cues: {_normalize_phrase(brief.strengths)}")
    if brief.notes:  core.append(f"tonality: {_normalize_phrase(brief.notes)}")

    if palette:
        hex_join = ", ".join(palette)
        core.append(f"restrict color palette to: {hex_join}")

    if sketch_present and mask_present:
        core += [
            "respect provided sketch silhouette and composition strictly",
            "align text to provided text mask: same baseline, curvature, kerning, tracking",
            "preserve relative scale and placement from guides",
        ]
    elif sketch_present and not mask_present:
        core += [
            "follow provided sketch for silhouette and composition",
            "typeset logo text centered relative to sketch focal point",
        ]
    elif (not sketch_present) and mask_present:
        core += [
            "follow provided text mask for baseline, curvature, arc radius and alignment",
            "wrap lettering along the guide curve if indicated",
        ]
    else:
        core += ["centered composition, strong focal hierarchy"]

    core += [
        "sdxl-friendly descriptors, logo design focus, graphic design, vector art look",
        "2D, plain background, studio lighting not applicable",
    ]
    return ", ".join(core)

def _build_negative_prompt(brief: PromptBrief) -> str:
    avoid_user = _normalize_phrase(brief.avoid)
    neg = [
        "photo, photorealistic, 3d render, depth of field, shadows, reflections",
        "noise, artifacts, blur, low-res, pixelation, aliasing, messy edges",
        "complex background, textured background, busy pattern",
        "too many colors, neon glow, bevel, emboss, chrome, gradient mesh",
        "drop shadow, lens flare, watermark, signature, stock icon",
        "illegible text, warped letters, inconsistent kerning, misaligned baseline",
    ]
    if avoid_user:
        neg.append(avoid_user)
    return ", ".join(neg)

def build_prompt_bundle(brief: PromptBrief, palette: Optional[List[str]],
                        sketch_present: bool, mask_present: bool) -> dict:
    logo_type = _infer_logo_type(brief.copy_text, brief.layout, brief.style)
    positive = _build_positive_prompt(brief, palette, logo_type, sketch_present, mask_present)
    negative = _build_negative_prompt(brief)

    control_hints = []
    if sketch_present:
        control_hints.append("Enable ControlNet(Scribble or Canny) with medium weight (e.g., 0.6â€“0.8)")
    if mask_present:
        control_hints.append("Compose text exactly along mask; keep baseline/arc/kerning identical")

    return {
        "model": "SDXL Base",
        "logo_type": logo_type,
        "positive": positive,
        "negative": negative,
        "control_hints": control_hints,
        "sampler": "DPM++ 2M Karras",
        "cfg_scale": 6.5,
        "steps": 30,
        "size": "1024x1024",
    }

# =============================
# ë°±ì—”ë“œ í˜¸ì¶œ
# =============================
def start_generate(
    brief_id: int,
    sketch_b64: Optional[str],
    mask_b64: Optional[str],
    text_info: Optional[Dict[str, Any]],
    prompt_overrides: Optional[dict],
    gpt_prompt_seed: Optional[str],
    gpt_messages: Optional[List[Dict[str, str]]],
    num_images: int = 4,
    seed: Optional[int] = None,
) -> Optional[str]:
    payload = {
        "brief_id": brief_id,
        "sketch_png_b64": sketch_b64,
        "text_mask_png_b64": mask_b64,
        "text_info": text_info,                         # ğŸ”‘ 2ë‹¨ê³„ì—ì„œ ë§Œë“  êµ¬ì¡°í™” í…ìŠ¤íŠ¸ ì •ë³´
        "use_llm_prompt": True,                         # ğŸ”‘ ë°±ì—”ë“œê°€ GPTë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        "llm_inputs": {                                 # ğŸ”‘ ë°±ì—”ë“œ LLMì— ì „ë‹¬í•  íŒíŠ¸ ë²ˆë“¤
            "prompt_overrides": prompt_overrides or {},
            "gpt_prompt_seed": gpt_prompt_seed or "",
            "gpt_messages": gpt_messages or [],         # (ë°±ì—”ë“œê°€ ì§€ì›í•˜ë©´ ì‚¬ìš©)
        },
        "num_images": int(num_images),
        "seed": seed,
        "return_debug": True,
    }
    try:
        r = requests.post(GENERATE_URL, json=payload, timeout=300)
        r.raise_for_status()
        data = r.json()
        return data.get("job_id")
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹œì‘ ì‹¤íŒ¨: {e}")
        return None

def poll_result(job_id: str, timeout_sec: int = 300, interval_sec: float = 2.0) -> Optional[List[str]]:
    t0 = time.time()
    with st.spinner("ì´ë¯¸ì§€ ìƒì„± ì¤‘â€¦"):
        while True:
            try:
                url = f"{BACKEND_BASE.rstrip('/')}{JOB_ENDPOINT.format(job_id=job_id)}"
                r = requests.get(url, timeout=300)
                if r.status_code == 404:
                    time.sleep(interval_sec)
                    if time.time() - t0 > timeout_sec:
                        st.error("ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”(404)."); return None
                    continue
                r.raise_for_status()
                data = r.json()
                status = data.get("status", "pending")
                if status == "done":
                    imgs = data.get("images_b64") or []
                    return imgs if imgs else None
                if status == "error":
                    st.error(f"ìƒì„± ì˜¤ë¥˜: {data.get('error')}"); return None
            except Exception as e:
                st.warning(f"í´ë§ ì—ëŸ¬: {e}")
            if time.time() - t0 > timeout_sec:
                st.warning("ìƒì„± ëŒ€ê¸° ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤."); return None
            time.sleep(interval_sec)

# =============================
# ë©”ì¸ ë Œë”
# =============================
def render():
    try:
        st.set_page_config(page_title=TITLE, page_icon="ğŸ“", layout="wide")
    except Exception:
        pass

    st.progress(75, text="Step 3/4 â€” Brief")
    st.title(TITLE)
    st.subheader("ğŸ“ ìš”êµ¬ì‚¬í•­ì„ ìƒì„¸í•˜ê²Œ ì…ë ¥í•´ ì£¼ì„¸ìš”")

    st.info(
        "ì´ ë‹¨ê³„ì—ì„œëŠ” **ìŠ¤ì¼€ì¹˜/í…ìŠ¤íŠ¸ ë§ˆìŠ¤í¬ ìœ ë¬´**ë¥¼ ê°ì§€í•´ SDXLìš© **LLM í”„ë¡¬í”„íŠ¸**ë¥¼ ìƒì„±í•˜ë„ë¡ ë°±ì—”ë“œì— í•„ìš”í•œ ì •ë³´ë¥¼ ëª¨ë‘ ì „ë‹¬í•©ë‹ˆë‹¤.\n"
        "ì°¸ê³  ì´ë¯¸ì§€ë¥¼ ì˜¬ë¦¬ë©´ **íŒ”ë ˆíŠ¸**ë¥¼ ì¶”ì¶œí•´ ìƒ‰ìƒì„ ì œí•œí•©ë‹ˆë‹¤."
    )

    # ì„¸ì…˜ ìƒíƒœ ê¸°ë³¸ê°’
    st.session_state.setdefault("brief_payload", None)
    st.session_state.setdefault("brief_id", None)
    st.session_state.setdefault("palette", None)
    st.session_state.setdefault("ref_img_b64", None)
    st.session_state.setdefault("gpt_prompt_seed", None)
    st.session_state.setdefault("prompt_bundle", None)

    # ===== ìŠ¤ì¼€ì¹˜/ë§ˆìŠ¤í¬ ê°ì§€ ë°°ì§€ =====
    sketch_b64 = None
    for k in ("sketch_png_b64","sketch_final_png_b64","sketch_canvas_b64","sketch_result_b64","sketch_rgba_b64","sketch_bytes_b64"):
        if st.session_state.get(k):
            sketch_b64 = st.session_state.get(k); break
    mask_b64 = st.session_state.get("mask_text_png_b64")

    col_badge1, col_badge2 = st.columns([1, 5])
    with col_badge1:
        st.caption("ê°€ì´ë“œ ê°ì§€")
    with col_badge2:
        s = "âœ… ìŠ¤ì¼€ì¹˜ ìˆìŒ" if sketch_b64 else "â¬œ ìŠ¤ì¼€ì¹˜ ì—†ìŒ"
        m = "âœ… í…ìŠ¤íŠ¸ ë§ˆìŠ¤í¬ ìˆìŒ" if mask_b64 else "â¬œ í…ìŠ¤íŠ¸ ë§ˆìŠ¤í¬ ì—†ìŒ"
        st.markdown(f"- {s}  \n- {m}")

    # ğŸ”‘ 2ë‹¨ê³„(Text)ì—ì„œ ë§Œë“  êµ¬ì¡°í™” ì •ë³´
    text_info: Optional[Dict[str, Any]] = st.session_state.get("text_info")
    if text_info is None:
        st.info("ì°¸ê³ : 2ë‹¨ê³„(Text)ì—ì„œ ë§Œë“  êµ¬ì¡°í™” í…ìŠ¤íŠ¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. (ì§ì„ /ì›í˜• í…ìŠ¤íŠ¸ ê°€ì´ë“œê°€ í”„ë¡¬í”„íŠ¸ì— ë°˜ì˜ë˜ì§€ ì•Šì„ ìˆ˜ ìˆì–´ìš”)")

    # ===== í¼ =====
    try:
        form_ctx = st.form(_k("form"), border=True)
    except TypeError:
        form_ctx = st.form(_k("form"))

    with form_ctx:
        col1, col2 = st.columns(2)
        with col1:
            cafe_name = st.text_input("ì¹´í˜ëª… *", value="BlueMoon", key=_k("cafe_name"))
            # 'ìƒì„±í•˜ê³  ì‹¶ì€ í…ìŠ¤íŠ¸'ì€ í…ìŠ¤íŠ¸ ë§ˆìŠ¤í¬ê°€ ìˆëŠ” ê²½ìš° í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
            mask_present = bool(st.session_state.get("mask_text_png_b64"))
            if not mask_present:
                copy_text = st.text_input("ìƒì„±í•˜ê³  ì‹¶ì€ í…ìŠ¤íŠ¸ *", value="BLUE MOON CAFE", key=_k("copy_text"))
            else:
                copy_text = ""
        with col2:
            strengths = st.text_input("í•µì‹¬ ì¥ì  *", value="ìŠ¤í˜ì…œí‹° ì›ë‘, ë‹¹ì¼ ë¡œìŠ¤íŒ…", key=_k("strengths"))
            style = st.text_input("ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ *", value="ë¯¸ë‹ˆë©€, ë²¡í„°, ë² ì´ì§€/ë¸Œë¼ìš´", key=_k("style"))
            notes = st.text_area("ìƒì„±í•˜ê³  ì‹¶ì€ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš” *", value="ê¹”ë”í•˜ê³  ë‹¨ìˆœí•˜ê²Œ. ì¸ì‡„ ì í•©.", height=90, key=_k("notes"))
            st.text_input("ì‚¬ìš©í•  ëª¨ë¸ (ìë™ ê³ ì •)", value="SDXL Base", key=_k("model_hint"), disabled=True)

        # ì´ë¯¸ì§€ ì—…ë¡œë“œ UI ë° íŒ”ë ˆíŠ¸ ì¶”ì¶œì€ í”„ë¡ íŠ¸ì—ì„œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.

        generate_now = st.form_submit_button("ì´ë¯¸ì§€ ìƒì„± â–¶", type="primary", use_container_width=True)

    # ===== ì…ë ¥ ê²€ì¦/í”„ë¦¬ë·°/í”„ë¡¬í”„íŠ¸ ìƒì„± =====
    def _prepare_and_preview() -> Tuple[Optional[PromptBrief], Optional[dict], Optional[str], Optional[dict], Optional[List[Dict[str,str]]]]:
        missing = []
        if not cafe_name.strip():   missing.append("ì¹´í˜ëª…")
        mask_present_local = bool(mask_b64)
        if not mask_present_local:
            if not copy_text.strip():   missing.append("ìƒì„±í•˜ê³  ì‹¶ì€ í…ìŠ¤íŠ¸")
        if not strengths.strip():   missing.append("í•µì‹¬ ì¥ì ")
        if not style.strip():      missing.append("ì›í•˜ëŠ” ìŠ¤íƒ€ì¼")
        if not notes.strip():       missing.append("ìƒì„±í•˜ê³  ì‹¶ì€ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”")
        if missing:
            st.error(f"í•„ìˆ˜ í•­ëª©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”: {', '.join(missing)}")
            return None, None, None, None, None

        brief = PromptBrief(
            cafe_name=cafe_name, copy_text=copy_text, layout="", avoid="",
            strengths=strengths, style=style, notes=notes, model_hint="SDXL Base"
        )

        ref_b64: Optional[str] = None
        palette_vals: Optional[List[str]] = None

        # ì°¸ê³  ì´ë¯¸ì§€ ì—…ë¡œë“œ UIë¥¼ ì œê±°í–ˆìŠµë‹ˆë‹¤ â€” í”„ë¡ íŠ¸ì—ì„œ ì°¸ì¡° ì´ë¯¸ì§€/íŒ”ë ˆíŠ¸ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        ref_b64 = None
        palette_vals = None

        st.session_state.ref_img_b64 = ref_b64
        st.session_state.palette     = palette_vals

        # ===== ë¸Œë¦¬í”„ ì €ì¥ í˜ì´ë¡œë“œ (ë°±ì—”ë“œì— ê¸°ë¡) =====
        payload = {
            "request_id": str(uuid.uuid4()),
            "cafe_name": cafe_name,
            "copy_text": copy_text,
            "layout": "",
            "avoid": "",
            "strengths": strengths,
            "style": style,
            "notes": notes,
            "model_hint": "SDXL Base",
            "palette": [],
            "ref_image_present": False,
            "ref_img_b64": None,
            "guides": {
                "sketch_present": bool(sketch_b64),
                "text_mask_present": bool(mask_b64),
            },
            # ğŸ”‘ 2ë‹¨ê³„ì—ì„œ ë§Œë“  êµ¬ì¡°í™” í…ìŠ¤íŠ¸ ì •ë³´ (LLM í”„ë¡¬í”„íŠ¸ ì»¨í…ìŠ¤íŠ¸ë¡œ ì¤‘ìš”)
            "text_info": st.session_state.get("text_info"),
        }
        st.session_state["brief_payload"] = payload

        # === ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë²ˆë“¤(LLM íŒíŠ¸/ì˜¤ë²„ë¼ì´ë“œìš©) ===
        prompt_bundle = build_prompt_bundle(
            brief=brief,
            palette=palette_vals,
            sketch_present=bool(sketch_b64),
            mask_present=bool(mask_b64),
        )
        st.session_state["prompt_bundle"] = prompt_bundle

        # === LLM ì…ë ¥ ì‹œë“œ ë° ë©”ì‹œì§€ (ë°±ì—”ë“œì—ì„œ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥) ===
        gpt_prompt_seed = (
            "You are a prompt engineer. Create a single best SDXL Base prompt for a cafe logo.\n"
            "Use concise visual keywords; vector/flat aesthetics; print-ready.\n"
            "Output only the prompt string, no explanations.\n\n"
            f"Cafe Name: {cafe_name}\n"
            f"Logo Text: {copy_text}\n"
            f"Key Strengths: {strengths}\n"
            f"Desired Style: {style}\n"
            f"Notes: {notes}\n"
            f"Palette (hex): {', '.join(palette_vals) if palette_vals else 'N/A'}\n"
            f"Guides: sketch={bool(sketch_b64)}, text_mask={bool(mask_b64)}\n"
            "Model: SDXL Base\n"
        )
        st.session_state["gpt_prompt_seed"] = gpt_prompt_seed

        # ğŸ”‘ ë°±ì—”ë“œì—ì„œ chat.completionsë¡œ ë°”ë¡œ ì“¸ ìˆ˜ ìˆëŠ” messages
        gpt_messages = [
            {
                "role": "system",
                "content": "You are a branding assistant that writes crisp, SDXL-friendly logo prompts. Respond in JSON {\"prompt\": string, \"neg\": string}."
            },
            {
                "role": "user",
                "content": json.dumps({
                    "brief": payload,
                    "text_info": st.session_state.get("text_info"),
                    "sketch_present": bool(sketch_b64),
                    "text_mask_present": bool(mask_b64),
                    "palette": [],
                }, ensure_ascii=False)
            }
        ]

        with st.expander("ğŸ” ì „ì†¡/ìƒì„± ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", expanded=False):
            st.markdown("**ë¸Œë¦¬í”„ ì €ì¥ í˜ì´ë¡œë“œ(JSON)**")
            st.code(json.dumps(payload, ensure_ascii=False, indent=2), language="json")
            st.markdown("**í”„ë¡¬í”„íŠ¸ ë²ˆë“¤ (positive / negative / control hints)**")
            st.code(json.dumps(prompt_bundle, ensure_ascii=False, indent=2), language="json")
            st.markdown("**LLM messages (ë°±ì—”ë“œìš© ì°¸ê³ )**")
            st.code(json.dumps(gpt_messages, ensure_ascii=False, indent=2), language="json")

        return brief, payload, ref_b64, prompt_bundle, gpt_messages

    # ===== ìƒì„± (ì €ì¥ â†’ ìƒì„± â†’ í´ë§ â†’ ë„¤ë¹„) =====
    if generate_now:
        brief, payload, _, prompt_bundle, gpt_messages = _prepare_and_preview()
        if brief is None:
            st.stop()

        # 1) ì €ì¥
        brief_id = None
        try:
            resp = requests.post(BRIEF_POST_URL, json=payload, timeout=300)
            if resp.ok:
                data = resp.json()
                brief_id = data.get("id")
                st.session_state["brief_id"] = brief_id
                st.toast(f"ë°±ì—”ë“œ ì €ì¥ ì™„ë£Œ (id={brief_id})", icon="âœ…")
            else:
                st.error(f"ë°±ì—”ë“œ ì €ì¥ ì‹¤íŒ¨: {resp.status_code} {resp.text}"); st.stop()
        except Exception as e:
            st.error(f"ë°±ì—”ë“œ ì—°ê²° ì‹¤íŒ¨: {e}"); st.stop()

        # 2) ìƒì„± ì‹œì‘ â€” ğŸ”‘ LLM í”„ë¡¬í”„íŠ¸ ìƒì„±ì— í•„ìš”í•œ ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ë¥¼ ì „ë‹¬
        job_id = start_generate(
            brief_id=brief_id,
            sketch_b64=sketch_b64,
            mask_b64=mask_b64,
            text_info=st.session_state.get("text_info"),
            prompt_overrides=prompt_bundle,             # ë°±ì—”ë“œê°€ ìš°ì„  ì˜¤ë²„ë¼ì´ë“œë¡œ ì‚¬ìš©í•˜ê±°ë‚˜ LLM íŒíŠ¸ë¡œ ë³‘í•©
            gpt_prompt_seed=st.session_state.get("gpt_prompt_seed"),
            gpt_messages=gpt_messages,                  # ë°±ì—”ë“œê°€ ì§€ì› ì‹œ ë°”ë¡œ ì‚¬ìš©
            num_images=4,
            seed=None,
        )
        if not job_id: st.stop()
        st.session_state["last_job_id"] = job_id

        # 3) í´ë§
        images_b64 = poll_result(job_id=job_id, timeout_sec=300, interval_sec=2.0)
        if images_b64 and isinstance(images_b64, list) and len(images_b64) > 0:
            st.session_state["gen_images_b64"] = images_b64
            st.success("ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ! ë‹¤ìŒ í˜ì´ì§€ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            _nav_to_next_step()
        else:
            st.warning("ìƒì„±ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ í˜ì´ì§€ì—ì„œ ë‹¤ì‹œ ì‹œë„í•  ìˆ˜ ìˆì–´ìš”.")
            _nav_to_next_step()

if __name__ == "__main__":
    render()
